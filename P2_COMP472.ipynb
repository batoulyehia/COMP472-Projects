{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "from __future__ import division\n",
    "from codecs import open\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read document\n",
    "# Ref: Project 2 instruction\n",
    "def read_documents(doc_file):\n",
    "    docs = []\n",
    "    labels = []\n",
    "    with open(doc_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line.strip().split()\n",
    "            #print(words)\n",
    "            docs.append(words[3:])\n",
    "            labels.append(words[1])\n",
    "    return docs, labels\n",
    "\n",
    "# Seperate list it by class\n",
    "def separate_by_class(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "# Get the sum of pos column\n",
    "def sum_total_pos(dataframe):\n",
    "    return dataframe['pos'].sum()\n",
    "\n",
    "# Get the sum of neg column\n",
    "def sum_total_neg(dataframe):\n",
    "    return dataframe['neg'].sum()\n",
    "\n",
    "# Smoothing dataframe\n",
    "def smooth_data_frame(dataframe):\n",
    "    dataframe['pos'] = dataframe['pos'].add(0.5)\n",
    "    dataframe['neg'] = dataframe['neg'].add(0.5)\n",
    "    return dataframe\n",
    "\n",
    "# Calculate logarithmic probability\n",
    "def calculate_probability(value,total):\n",
    "    return np.log(value/total)\n",
    "\n",
    "# Calculate logarithmic probabilities for dataframe\n",
    "def calculate_probabilities(dataframe):\n",
    "    sum_pos = sum_total_pos(dataframe)\n",
    "    print(sum_pos)\n",
    "    sum_neg = sum_total_neg(dataframe)\n",
    "    dataframe['pos'] =  np.log(dataframe['pos'] / sum_pos)\n",
    "    dataframe['neg'] =  np.log(dataframe['neg'] / sum_neg)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Add label to docs\n",
    "def add_label_to_docs(docs,labels):\n",
    "    for index in range(len(docs)):\n",
    "        docs[index].append(labels[index])\n",
    "    return docs\n",
    "\n",
    "def train_nb(documents, labels):\n",
    "    #return the data you need to classify new instances\n",
    "    new_docs = add_label_to_docs(documents,labels)\n",
    "    # Separate docs by label\n",
    "    train_docs = np.array(documents)\n",
    "    seperate = separate_by_class(documents)\n",
    "    train_docs_neg_freqs = Counter(w for doc in seperate['neg'] for w in doc)\n",
    "    train_docs_pos_freqs = Counter(w for doc in seperate['pos'] for w in doc)\n",
    "    df_neg = pd.DataFrame.from_dict(train_docs_neg_freqs, orient='index').reset_index()\n",
    "    df_neg = df_neg.rename(columns={'index':'word', 0:'neg'})\n",
    "    df_pos = pd.DataFrame.from_dict(train_docs_pos_freqs, orient='index').reset_index()\n",
    "    df_pos = df_pos.rename(columns={'index':'word', 0:'pos'})\n",
    "    \n",
    "    # Union Join two dataframe\n",
    "    # Ref: https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/\n",
    "    df_merge = pd.merge(df_neg,df_pos,on='word',how='outer')\n",
    "    df_merge = df_merge.fillna(0)\n",
    "    print('Before smoothing:\\n',df_merge)\n",
    "    df_merge = smooth_data_frame(df_merge)\n",
    "    print('After smoothing:\\n',df_merge)\n",
    "    df_probablities=calculate_probabilities(df_merge).set_index('word')\n",
    "\n",
    "    # calculate the probabilities\n",
    "    num_pos_doc=labels.count('pos')\n",
    "    num_neg_doc=labels.count('neg')\n",
    "\n",
    "    before_prob_dic={'pos':np.log(num_pos_doc/(num_pos_doc+num_neg_doc)),\n",
    "                    'neg':np.log(num_neg_doc/(num_pos_doc+num_neg_doc))}\n",
    "\n",
    "\n",
    "    return df_probablities,before_prob_dic\n",
    "\n",
    "\n",
    "def score_doc_label(document, label, params):\n",
    "    '''\n",
    "    # (return the log probability)\n",
    "    '''\n",
    "    df_probablities,before_prob_dic=params\n",
    "    p_log=before_prob_dic[label] #with the probabilities from above\n",
    "    for w in document:\n",
    "        try:\n",
    "            p_log+=df_probablities.loc[w,label] #increasing the conditional probabilities\n",
    "        except:\n",
    "            pass #if the word does not exist in the model, do not count it\n",
    "    p=np.exp(p_log)\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def classify_nb(document, params):\n",
    "    '''\n",
    "    (return the guess of the classifier)\n",
    "    '''\n",
    "    # check the score\n",
    "    pos_score=score_doc_label(document,'pos',params)\n",
    "    neg_score=score_doc_label(document,'neg',params)\n",
    "\n",
    "    label='pos' if pos_score>neg_score else 'neg'\n",
    "    return label\n",
    "\n",
    "\n",
    "def classify_documents(docs, params):\n",
    "    '''\n",
    "    (return the classifier's predictions for all documents in the collection)\n",
    "    '''\n",
    "    guessed_labels=[]\n",
    "    for document in docs:\n",
    "        guessed_labels.append(classify_nb(document,params))\n",
    "    return guessed_labels\n",
    "\n",
    "\n",
    "def accuracy(true_labels, guessed_labels):\n",
    "    '''...\n",
    "    (return the accuracy)\n",
    "    '''\n",
    "    correct_num=0\n",
    "    for t,g in zip(true_labels,guessed_labels):\n",
    "        # check the correctness\n",
    "        correct_num+=(t==g)\n",
    "    # accuracy\n",
    "    acc=correct_num/len(true_labels)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Read docs\n",
    "all_docs, all_labels = read_documents('all_sentiment_shuffled.txt')\n",
    "\n",
    "\n",
    "# 2.This split first 80% of data as training set, and the rest 20% will be evaluation set\n",
    "split_point = int(0.8*len(all_docs))\n",
    "train_docs = all_docs[:split_point]\n",
    "train_labels = all_labels[:split_point]\n",
    "eval_docs = all_docs[split_point:]\n",
    "eval_labels = all_labels[split_point:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before smoothing:\n",
      "                            word      neg      pos\n",
      "0                             i  16707.0  14814.0\n",
      "1                        bought    686.0    543.0\n",
      "2                          this   9608.0   9391.0\n",
      "3                         album    733.0    882.0\n",
      "4                       because   1183.0    897.0\n",
      "5                         loved    125.0    181.0\n",
      "6                           the  31914.0  33502.0\n",
      "7                         title    110.0     95.0\n",
      "8                          song    366.0    498.0\n",
      "9                             .  30682.0  29981.0\n",
      "10                           it  12338.0  11728.0\n",
      "11                           's   4769.0   5309.0\n",
      "12                         such    453.0    404.0\n",
      "13                            a  14857.0  16184.0\n",
      "14                        great    824.0   2008.0\n",
      "15                            ,  26333.0  27532.0\n",
      "16                          how    941.0    881.0\n",
      "17                          bad    709.0    261.0\n",
      "18                          can   1378.0   1891.0\n",
      "19                         rest    191.0    118.0\n",
      "20                           of  12895.0  14207.0\n",
      "21                           be   3082.0   2698.0\n",
      "22                        right    367.0    386.0\n",
      "23                            ?   1548.0    729.0\n",
      "24                         well    812.0   1277.0\n",
      "25                        songs    418.0    468.0\n",
      "26                          are   3469.0   3641.0\n",
      "27                         just   2021.0   1668.0\n",
      "28                       filler     30.0      8.0\n",
      "29                          and  15970.0  18754.0\n",
      "...                         ...      ...      ...\n",
      "52364                       m&a      0.0      1.0\n",
      "52365                 bloodflow      0.0      1.0\n",
      "52366                     15lbs      0.0      1.0\n",
      "52367               afforadable      0.0      1.0\n",
      "52368                     marko      0.0      1.0\n",
      "52369                    ramius      0.0      1.0\n",
      "52370                   dutiful      0.0      1.0\n",
      "52371                    petrov      0.0      1.0\n",
      "52372               histrionics      0.0      1.0\n",
      "52373                     neill      0.0      3.0\n",
      "52374                    vasily      0.0      1.0\n",
      "52375                   borodin      0.0      1.0\n",
      "52376                   mancuso      0.0      1.0\n",
      "52377                      pelt      0.0      1.0\n",
      "52378                     putin      0.0      1.0\n",
      "52379                pragmatism      0.0      1.0\n",
      "52380                   bolster      0.0      1.0\n",
      "52381                 dramatics      0.0      1.0\n",
      "52382                 escellent      0.0      1.0\n",
      "52383                      rell      0.0      2.0\n",
      "52384               extremeties      0.0      1.0\n",
      "52385                     fiero      0.0      4.0\n",
      "52386                 mcqueen's      0.0      1.0\n",
      "52387                   thorson      0.0      1.0\n",
      "52388                    mcquen      0.0      1.0\n",
      "52389                   handbag      0.0      1.0\n",
      "52390  geraldkalisik@hotmail.co      0.0      1.0\n",
      "52391                    schama      0.0      1.0\n",
      "52392               conditioned      0.0      1.0\n",
      "52393                strenghten      0.0      1.0\n",
      "\n",
      "[52394 rows x 3 columns]\n",
      "After smoothing:\n",
      "                            word      neg      pos\n",
      "0                             i  16707.5  14814.5\n",
      "1                        bought    686.5    543.5\n",
      "2                          this   9608.5   9391.5\n",
      "3                         album    733.5    882.5\n",
      "4                       because   1183.5    897.5\n",
      "5                         loved    125.5    181.5\n",
      "6                           the  31914.5  33502.5\n",
      "7                         title    110.5     95.5\n",
      "8                          song    366.5    498.5\n",
      "9                             .  30682.5  29981.5\n",
      "10                           it  12338.5  11728.5\n",
      "11                           's   4769.5   5309.5\n",
      "12                         such    453.5    404.5\n",
      "13                            a  14857.5  16184.5\n",
      "14                        great    824.5   2008.5\n",
      "15                            ,  26333.5  27532.5\n",
      "16                          how    941.5    881.5\n",
      "17                          bad    709.5    261.5\n",
      "18                          can   1378.5   1891.5\n",
      "19                         rest    191.5    118.5\n",
      "20                           of  12895.5  14207.5\n",
      "21                           be   3082.5   2698.5\n",
      "22                        right    367.5    386.5\n",
      "23                            ?   1548.5    729.5\n",
      "24                         well    812.5   1277.5\n",
      "25                        songs    418.5    468.5\n",
      "26                          are   3469.5   3641.5\n",
      "27                         just   2021.5   1668.5\n",
      "28                       filler     30.5      8.5\n",
      "29                          and  15970.5  18754.5\n",
      "...                         ...      ...      ...\n",
      "52364                       m&a      0.5      1.5\n",
      "52365                 bloodflow      0.5      1.5\n",
      "52366                     15lbs      0.5      1.5\n",
      "52367               afforadable      0.5      1.5\n",
      "52368                     marko      0.5      1.5\n",
      "52369                    ramius      0.5      1.5\n",
      "52370                   dutiful      0.5      1.5\n",
      "52371                    petrov      0.5      1.5\n",
      "52372               histrionics      0.5      1.5\n",
      "52373                     neill      0.5      3.5\n",
      "52374                    vasily      0.5      1.5\n",
      "52375                   borodin      0.5      1.5\n",
      "52376                   mancuso      0.5      1.5\n",
      "52377                      pelt      0.5      1.5\n",
      "52378                     putin      0.5      1.5\n",
      "52379                pragmatism      0.5      1.5\n",
      "52380                   bolster      0.5      1.5\n",
      "52381                 dramatics      0.5      1.5\n",
      "52382                 escellent      0.5      1.5\n",
      "52383                      rell      0.5      2.5\n",
      "52384               extremeties      0.5      1.5\n",
      "52385                     fiero      0.5      4.5\n",
      "52386                 mcqueen's      0.5      1.5\n",
      "52387                   thorson      0.5      1.5\n",
      "52388                    mcquen      0.5      1.5\n",
      "52389                   handbag      0.5      1.5\n",
      "52390  geraldkalisik@hotmail.co      0.5      1.5\n",
      "52391                    schama      0.5      1.5\n",
      "52392               conditioned      0.5      1.5\n",
      "52393                strenghten      0.5      1.5\n",
      "\n",
      "[52394 rows x 3 columns]\n",
      "751940.0\n",
      "                                neg        pos\n",
      "word                                          \n",
      "i                         -3.798596  -3.927050\n",
      "bought                    -6.990602  -7.232382\n",
      "this                      -4.351805  -4.382852\n",
      "album                     -6.924381  -6.747653\n",
      "because                   -6.445977  -6.730799\n",
      "loved                     -8.689903  -8.329156\n",
      "the                       -3.151393  -3.111036\n",
      "title                     -8.817193  -8.971286\n",
      "song                      -7.618210  -7.318808\n",
      ".                         -3.190761  -3.222076\n",
      "it                        -4.101729  -4.160635\n",
      "'s                        -5.052212  -4.953159\n",
      "such                      -7.405213  -7.527760\n",
      "a                         -3.915949  -3.838603\n",
      "great                     -6.807432  -5.925268\n",
      ",                         -3.343612  -3.307289\n",
      "how                       -6.674734  -6.748787\n",
      "bad                       -6.957648  -7.963978\n",
      "can                       -6.293457  -5.985286\n",
      "rest                      -8.267321  -8.755499\n",
      "of                        -4.057575  -3.968887\n",
      "be                        -5.488712  -5.629960\n",
      "right                     -7.615485  -7.573280\n",
      "?                         -6.177167  -6.938052\n",
      "well                      -6.822093  -6.377751\n",
      "songs                     -7.485532  -7.380876\n",
      "are                       -5.370443  -5.330261\n",
      "just                      -5.910614  -6.110732\n",
      "filler                   -10.104482 -11.390346\n",
      "and                       -3.843710  -3.691223\n",
      "...                             ...        ...\n",
      "m&a                      -14.215356 -13.124947\n",
      "bloodflow                -14.215356 -13.124947\n",
      "15lbs                    -14.215356 -13.124947\n",
      "afforadable              -14.215356 -13.124947\n",
      "marko                    -14.215356 -13.124947\n",
      "ramius                   -14.215356 -13.124947\n",
      "dutiful                  -14.215356 -13.124947\n",
      "petrov                   -14.215356 -13.124947\n",
      "histrionics              -14.215356 -13.124947\n",
      "neill                    -14.215356 -12.277649\n",
      "vasily                   -14.215356 -13.124947\n",
      "borodin                  -14.215356 -13.124947\n",
      "mancuso                  -14.215356 -13.124947\n",
      "pelt                     -14.215356 -13.124947\n",
      "putin                    -14.215356 -13.124947\n",
      "pragmatism               -14.215356 -13.124947\n",
      "bolster                  -14.215356 -13.124947\n",
      "dramatics                -14.215356 -13.124947\n",
      "escellent                -14.215356 -13.124947\n",
      "rell                     -14.215356 -12.614121\n",
      "extremeties              -14.215356 -13.124947\n",
      "fiero                    -14.215356 -12.026334\n",
      "mcqueen's                -14.215356 -13.124947\n",
      "thorson                  -14.215356 -13.124947\n",
      "mcquen                   -14.215356 -13.124947\n",
      "handbag                  -14.215356 -13.124947\n",
      "geraldkalisik@hotmail.co -14.215356 -13.124947\n",
      "schama                   -14.215356 -13.124947\n",
      "conditioned              -14.215356 -13.124947\n",
      "strenghten               -14.215356 -13.124947\n",
      "\n",
      "[52394 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train model get a dataframe which contains probabilities after smoothing and log\n",
    "df_probablities,before_prob_dic =train_nb(train_docs,train_labels)\n",
    "print(df_probablities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <SOMETHING> task1's return \n",
    "params=(df_probablities,before_prob_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001358386003932884 0.0005433109334758503\n"
     ]
    }
   ],
   "source": [
    "# sanity check1\n",
    "very_short_doc=['great']\n",
    "pos_prob=score_doc_label(very_short_doc,'pos',params)\n",
    "neg_prob=score_doc_label(very_short_doc,'neg',params)\n",
    "\n",
    "print(pos_prob,neg_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.889535085317261e-06 1.4637191643382007e-06\n"
     ]
    }
   ],
   "source": [
    "# sanity check2\n",
    "very_short_doc=['a','top-quality','performance']\n",
    "pos_prob=score_doc_label(very_short_doc,'pos',params)\n",
    "neg_prob=score_doc_label(very_short_doc,'neg',params)\n",
    "\n",
    "print(pos_prob,neg_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall acc is  0.6953420058749475\n"
     ]
    }
   ],
   "source": [
    "# overall acc\n",
    "guessed_labels=classify_documents(eval_docs,params)\n",
    "overall_acc=accuracy(eval_labels,guessed_labels)\n",
    "print('Overall acc is ',overall_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "      <th>All</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>529</td>\n",
       "      <td>1153</td>\n",
       "      <td>0.458803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1128</td>\n",
       "      <td>1230</td>\n",
       "      <td>0.917073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Correct   All  Accuracy\n",
       "positive      529  1153  0.458803\n",
       "negative     1128  1230  0.917073"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Give a table of results showing the accuracy for each class\n",
    "pos_correct,neg_correct=0,0 #the correctness from pos and neg\n",
    "pos_all,neg_all=0,0 #the overall records from pos and neg\n",
    "\n",
    "for guess,true in zip(guessed_labels,eval_labels):\n",
    "    if true=='pos':   \n",
    "        pos_all+=1\n",
    "        if guess=='pos':\n",
    "            pos_correct+=1\n",
    "    elif true=='neg':   \n",
    "        neg_all+=1\n",
    "        if guess=='neg':\n",
    "            neg_correct+=1\n",
    "\n",
    "pos_acc=pos_correct/pos_all\n",
    "neg_acc=neg_correct/neg_all\n",
    "df_table=pd.DataFrame([[pos_correct,pos_all,pos_acc],\n",
    "                       [neg_correct,neg_all,neg_acc]],\n",
    "                     columns=['Correct','All','Accuracy'],\n",
    "                     index=['positive','negative'])\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the observation, pos' accuracy is much less than neg's. The reason could be the positve comments from the modle is less than expected, therefore, it disturbs the modle's judment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
